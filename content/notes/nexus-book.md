---
title: Nexus book notes
tags:
  - notes
  - books
---
The book _Nexus: A Brief History of Information Networks from the Stone Age to AI_ by Yuval Noah Harari is about exactly what it says. 

Its main thesis is that information is a binding agent in social networks, which in order to grow need to balance between truth and order, or from another perspective, wisdom and power. An optimization in one direction is inherently a compromise in the other. I'm not too sure I agree with that part, at least in that it's a direct 1:1 mapping. 

His definition of the "naive view of information" is the common trope that more information will yield truth. He claims this is false, and the process of combating false information is to add more information, or the natural emergence of truth is through more and more information. 

Information networks are said to be held together by "myths" and "bureaucracy." That is, the myths are the stories that are told that define the intersubjective realities, while the bureaucracy is the process by which it maintains order and grows itself. 

He writes that discovering and working towards truth, which is defined as a representation of objective reality, is a very difficult and cumbersome process, whereas misinformation is easy and trivial to create and in some cases, easier to control social networks with. 

>[!NOTE] Anyone can say an untruth in an instant, and it takes much more time to prove it wrong or right. 

Additionally, any individual truth is inherently incomplete. It is some level of abstraction from the reality that exists. 

He defines three types of reality:
1. objective reality - President Lincoln was shot in the head, the moon orbits the earth
2. subjective reality - "Okra tastes good"
3. intersubjective reality - the US dollar, or bitcoin, has value

Information networks are said to be held together by "myths" and "bureaucracy." That is, the myths are the stories that are told that define the intersubjective realities, while the bureaucracy is the process by which it maintains order and grows itself. 

We have developed tools over the ages that have grown our ability to create information networks:
1. Stories - binding tribes together through shared narrative, but ultimately difficult to pass around and stay the same
2. Documents - keeping the story the same throughout the ages while also allowing for larger complexity because it doesn't need to be all kept in the brain and shared through story-tellers, but ultimately leads to bureaucracy which has a masking effect on how the system works. 

Documents lead to books, which are important in that they are the same piece of information that spreads without (hopefully), change. These are used as central pillars to large information networks to create the intersubjective reality of the network. 

It is important to note that even these books are subject to the infallibility of humans. 

>[!QUOTE] While churches made decisions about texts, the texts themselves shaped the churches

He then goes on to explain that the free flow of information doesn't always lead to truth (the naive interpretation of information). He does this by comparing the growth of witch hunts and related conspiracies vs the growth of the scientific revolution via the invention of the printing press. The former influence was from a book _The Hammer of the Witches_, which sold out and was widespread, instantly, leading to multiple versions and editions, leading to cult like fantasies and inquisitions against witches, killing tens of thousands of innocent people, even children. Even today, our modern vision of what witches are is shaped by this book and its cultural influence. 

On the other hand, Copernicus''s _On the Revolutions of the Heavenly Bodies_ was hailed as "an all-time worst seller" by Arthur Koestler. 

The way a given information network tends towards truth is through the institutional process of acknowledging its ignorance. This is manifest in the scientific enterprise. A key point in information networks that do self-correct but aren't scientific enterprises are that corrections are blamed on individual's interpretations, as there isn't fault in the institution itself. An example of this would be the Catholic church changing its doctrine over time, but always via the excuse that individuals within the church were misinterpreting the _actual_ word of God. A scientific institution will not only publish things it got wrong, it will celebrate them. Self criticism is an important aspect of a healthy self-correcting information network.

This, although, comes at the cost of order. As a "strong self-correcting mechanism tends towards disagreements, arguments, conflicts, and rifts."

The next part of the book going into how strong/large information networks can lead towards two extremes: democratic and authoritarian/totalitarianism governments. These extremes are differentiated by how information flows. Democratic has a decentralized and competing landscape of information sources, which authoritarian regimes force all information to flow through a central party. Each of these have various benefits and consequences in terms of holding control and power, despite the fact that authoritarian regimes have no desire to find truth, only optimize for control. 

He uses Nazi Germany and Stalin's U.S.S.R.'s history to go through how effective these regimes were at controlling large groups of people. 

One trade-off is effienciency of decision making. Authoritarian regimes are very efficient at making decisions and following through with the, as they're done by a single central party, and there _can't_ be dissent, whereas democratic decisions making is slower and harder to do because it fosters differing opinions and checks and balances of power. 

Another is resilience. If you bottleneck an authoritarian decision making process, it falls apart completely. This seems to be an inevitability because those underneath are afraid of giving bad information, thus withholding information so they don't get in trouble (killed). 